optimizer_config:
    optimizer:
        class_path: torch.optim.AdamW
        init_args:
            lr: 1e-4
            weight_decay: 1e-4
    lr_scheduler:
        scheduler:
            class_path: torch.optim.lr_scheduler.MultiStepLR
            init_args:
                milestones: [8, 11]
        warmup_config:
            warmup_iters: 500

trainer:
    max_epochs: 12
